{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bae9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "103a9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETTINGS\n",
    "# download_pictures = False\n",
    "# meme_number = 1000 # limited to 1000 by PRAW -> use pushshift API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb8cab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_date(submission):\n",
    "#     time = submission.created\n",
    "#     return datetime.datetime.fromtimestamp(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a319d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_image(url):\n",
    "    \n",
    "#     file_name = url.split(\"/\")[-1]\n",
    "#     res = requests.get(url, stream = True)\n",
    "\n",
    "#     # Creating an images folder if it doens't already exist\n",
    "#     if not os.path.exists('images'):\n",
    "#        os.makedirs('images')\n",
    "\n",
    "#     urllib.request.urlretrieve(url, \"images/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "892e5d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reddit_read_only = praw.Reddit(\n",
    "#     client_id='JzbofoB1-Xrh3gbv--LVTQ',\n",
    "#     client_secret='v3R81WmJnSJJ8WWdjn4sZvRcerIVGg',\n",
    "#     user_agent='Ukraine Scraper'\n",
    "# )\n",
    "# # qwerrtty423499 username\n",
    "# # KVKb6AqeabAG2PD password\n",
    "# # cveodyiphyxqccujnc@tmmbt.com email\n",
    "# # v3R81WmJnSJJ8WWdjn4sZvRcerIVGg secret\n",
    "\n",
    "# subreddit = reddit_read_only.subreddit(\"memes\")\n",
    "\n",
    "# # posts = subreddit.hot(limit=10)\n",
    "# posts = subreddit.top(time_filter='year', limit=meme_number)\n",
    "# # Scraping the top posts of the current month\n",
    "\n",
    "\n",
    "\n",
    "# posts_dict = {\"Title\": [], \"Author\" : [], \"Timestamp\" : [], \"Post Text\": [],\n",
    "#             \"ID\": [], \"Score\": [],\n",
    "#             \"Total Comments\": [], \"Image URL\": []\n",
    "#             }\n",
    "# # t = tqdm(total=meme_number, bar_format='{l_bar}{bar:50}{r_bar}{bar:-1b}')\n",
    "# t = tqdm(total=meme_number, bar_format='{l_bar}{bar:50}{r_bar}{bar:-1b}')\n",
    "# with t as progress_bar:\n",
    "#     for post in posts:\n",
    "#         # URL of each post\n",
    "#         # ensures posts without images are ignored\n",
    "#         if (\".jpg\" in post.url or \".png\" in post.url or \".tiff\" in post.url or \".gif\" in post.url):\n",
    "#             # image is valid\n",
    "#             posts_dict[\"Image URL\"].append(str(post.url))\n",
    "#             if (download_pictures):\n",
    "#                 download_pictures(str(post.url))\n",
    "\n",
    "#         else:\n",
    "#             progress_bar.update()\n",
    "#             continue \n",
    "\n",
    "#         # Title of each post\n",
    "#         posts_dict[\"Title\"].append(post.title)\n",
    "\n",
    "#         # Author of each post\n",
    "#         posts_dict[\"Author\"].append(str(post.author))\n",
    "\n",
    "#         # Time post was created\n",
    "#         posts_dict[\"Timestamp\"].append(datetime.datetime.fromtimestamp(post.created).strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "\n",
    "#         # Text inside a post\n",
    "#         posts_dict[\"Post Text\"].append(post.selftext)\n",
    "\n",
    "#         # Unique ID of each post\n",
    "#         posts_dict[\"ID\"].append(post.id)\n",
    "\n",
    "#         # The score of a post\n",
    "#         posts_dict[\"Score\"].append(post.score)\n",
    "\n",
    "#         # Total number of comments inside the post\n",
    "#         posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "        \n",
    "#         progress_bar.update()\n",
    "\n",
    "\n",
    "# # Displaying the data in a pandas dataframe (for testing purposes)\n",
    "# # pd.set_option('display.max_rows', 100)\n",
    "# # pd.set_option('max_colwidth', None)\n",
    "\n",
    "# # top_posts = pd.DataFrame(posts_dict)\n",
    "# # top_posts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96cdc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- MEMES FROM THE \"ukrainememes\" SUBREDDIT -------\n",
    "def write_data(posts_dict):\n",
    "    workbook = xlsxwriter.Workbook('ukrainememes_subreddit.xlsx')\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    # column, row\n",
    "\n",
    "    # Writing the table headers\n",
    "    i = 0\n",
    "    for key in posts_dict:\n",
    "        worksheet.write(0, i, key)\n",
    "        i+=1\n",
    "\n",
    "    # Writing the table data\n",
    "    for x in range(1, len(posts_dict[\"Title\"])):\n",
    "        i = 0\n",
    "        for key in posts_dict:\n",
    "            if (key == \"Image URL\"):\n",
    "                worksheet.write_url(x, i, posts_dict[key][x])\n",
    "            else:\n",
    "                worksheet.write(x, i, posts_dict[key][x])\n",
    "            i+=1\n",
    "\n",
    "    # Saving the document\n",
    "    workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efb37b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- MEMES FROM THE \"ukrainememes\" SUBREDDIT -------\n",
    "def read_posts(post_list, posts_dict):\n",
    "    for post in post_list:\n",
    "        \n",
    "        if (\".jpg\" in post[\"url\"] or \".png\" in post[\"url\"] or \".tiff\" in post[\"url\"] or \".gif\" in post[\"url\"]):\n",
    "            posts_dict[\"Image URL\"].append(str(post[\"url\"]))\n",
    "#             if (download_pictures):\n",
    "#                 download_pictures(str(post[\"url\"]))\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "        # Title of each post\n",
    "        posts_dict[\"Title\"].append(post[\"title\"])\n",
    "\n",
    "        # Author of each post\n",
    "        posts_dict[\"Author\"].append(str(post[\"author\"]))\n",
    "\n",
    "        # Time post was created\n",
    "        posts_dict[\"Timestamp\"].append(datetime.datetime.fromtimestamp(post[\"created_utc\"]).strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "\n",
    "        # Text inside a post\n",
    "        posts_dict[\"Post Text\"].append(post[\"selftext\"])\n",
    "\n",
    "        # Unique ID of each post\n",
    "        posts_dict[\"ID\"].append(post[\"id\"])\n",
    "\n",
    "        # The score of a post\n",
    "        posts_dict[\"Score\"].append(post[\"score\"])\n",
    "\n",
    "        # Total number of comments inside the post\n",
    "        posts_dict[\"Total Comments\"].append(str(post[\"num_comments\"]))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83333027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1673222280.3338306\n"
     ]
    }
   ],
   "source": [
    "# ------- MEMES FROM THE \"ukrainememes\" SUBREDDIT -------\n",
    "\n",
    "from pmaw import PushshiftAPI\n",
    "# http://web.archive.org/web/20210123052853/https://pushshift.io/api-parameters/\n",
    "# https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/\n",
    "\n",
    "api = PushshiftAPI()\n",
    "print(time.time())\n",
    "\n",
    "# Settings\n",
    "subreddit = \"ukrainememes\"\n",
    "chunk_size = 100\n",
    "reps = 3\n",
    "\n",
    "posts_dict = {\n",
    "    \"Title\": [], \"Author\" : [], \"Timestamp\" : [], \"Post Text\": [], \n",
    "    \"ID\": [], \"Score\": [], \"Total Comments\": [], \"Image URL\": []\n",
    "}\n",
    "    \n",
    "# Iterating over the returned list of submissions\n",
    "for x in range(reps):\n",
    "    if (x == 0):\n",
    "        last_time = int(time.time())\n",
    "    else:\n",
    "        if (len(post_list) != 0):\n",
    "            last_time = post_list[-1][\"created_utc\"]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    posts = api.search_submissions(\n",
    "        subreddit=subreddit, \n",
    "        limit=chunk_size,\n",
    "        before=last_time,\n",
    "        sort=\"desc\",\n",
    "        sort_type=\"created_utc\"\n",
    "    )\n",
    "    post_list = [post for post in posts]\n",
    "    read_posts(post_list, posts_dict)\n",
    "\n",
    "# Displaying the data in a pandas dataframe (for testing purposes)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts\n",
    "\n",
    "# Writing the data to excel\n",
    "write_data(posts_dict)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e404c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
