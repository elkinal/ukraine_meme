{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "download_pictures = False\n",
    "meme_number = 1000 # limited to 1000 by PRAW -> use pushshift API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8cab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(submission):\n",
    "    time = submission.created\n",
    "    return datetime.datetime.fromtimestamp(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(url):\n",
    "    \n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    res = requests.get(url, stream = True)\n",
    "\n",
    "    # Creating an images folder if it doens't already exist\n",
    "    if not os.path.exists('images'):\n",
    "       os.makedirs('images')\n",
    "\n",
    "    urllib.request.urlretrieve(url, \"images/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e5d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reddit_read_only = praw.Reddit(\n",
    "    client_id='JzbofoB1-Xrh3gbv--LVTQ',\n",
    "    client_secret='v3R81WmJnSJJ8WWdjn4sZvRcerIVGg',\n",
    "    user_agent='Ukraine Scraper'\n",
    ")\n",
    "# qwerrtty423499 username\n",
    "# KVKb6AqeabAG2PD password\n",
    "# cveodyiphyxqccujnc@tmmbt.com email\n",
    "# v3R81WmJnSJJ8WWdjn4sZvRcerIVGg secret\n",
    "\n",
    "subreddit = reddit_read_only.subreddit(\"memes\")\n",
    "\n",
    "# posts = subreddit.hot(limit=10)\n",
    "posts = subreddit.top(time_filter='year', limit=meme_number)\n",
    "# Scraping the top posts of the current month\n",
    "\n",
    "\n",
    "\n",
    "posts_dict = {\"Title\": [], \"Author\" : [], \"Timestamp\" : [], \"Post Text\": [],\n",
    "            \"ID\": [], \"Score\": [],\n",
    "            \"Total Comments\": [], \"Image URL\": []\n",
    "            }\n",
    "# t = tqdm(total=meme_number, bar_format='{l_bar}{bar:50}{r_bar}{bar:-1b}')\n",
    "t = tqdm(total=meme_number, bar_format='{l_bar}{bar:50}{r_bar}{bar:-1b}')\n",
    "with t as progress_bar:\n",
    "    for post in posts:\n",
    "        # URL of each post\n",
    "        # ensures posts without images are ignored\n",
    "        if (\".jpg\" in post.url or \".png\" in post.url or \".tiff\" in post.url or \".gif\" in post.url):\n",
    "            # image is valid\n",
    "            posts_dict[\"Image URL\"].append(str(post.url))\n",
    "            if (download_pictures):\n",
    "                download_pictures(str(post.url))\n",
    "\n",
    "        else:\n",
    "            progress_bar.update()\n",
    "            continue \n",
    "\n",
    "        # Title of each post\n",
    "        posts_dict[\"Title\"].append(post.title)\n",
    "\n",
    "        # Author of each post\n",
    "        posts_dict[\"Author\"].append(str(post.author))\n",
    "\n",
    "        # Time post was created\n",
    "        posts_dict[\"Timestamp\"].append(datetime.datetime.fromtimestamp(post.created).strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "\n",
    "        # Text inside a post\n",
    "        posts_dict[\"Post Text\"].append(post.selftext)\n",
    "\n",
    "        # Unique ID of each post\n",
    "        posts_dict[\"ID\"].append(post.id)\n",
    "\n",
    "        # The score of a post\n",
    "        posts_dict[\"Score\"].append(post.score)\n",
    "\n",
    "        # Total number of comments inside the post\n",
    "        posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "        \n",
    "        progress_bar.update()\n",
    "\n",
    "\n",
    "# Displaying the data in a pandas dataframe (for testing purposes)\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "# pd.set_option('max_colwidth', None)\n",
    "\n",
    "# top_posts = pd.DataFrame(posts_dict)\n",
    "# top_posts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb = Workbook()\n",
    "# sheet1 = wb.add_sheet('Reddit Data 1')\n",
    "workbook = xlsxwriter.Workbook('Expenses01.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# column, row\n",
    "\n",
    "# Writing the table headers\n",
    "i = 0\n",
    "for key in posts_dict:\n",
    "    worksheet.write(0, i, key)\n",
    "    i+=1\n",
    "\n",
    "# Writing the table data\n",
    "for x in range(1, len(posts_dict[\"Title\"])):\n",
    "    i = 0\n",
    "    for key in posts_dict:\n",
    "        if (key == \"Image URL\"):\n",
    "            worksheet.write_url(x, i, posts_dict[key][x])\n",
    "        else:\n",
    "            worksheet.write(x, i, posts_dict[key][x])\n",
    "        i+=1\n",
    "\n",
    "# Saving the document\n",
    "workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb37b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_posts(post_list, posts_dict):\n",
    "    for post in post_list:\n",
    "#         print(post[\"author\"] + \" \" + post[\"url\"] + \" \" + str(post[\"created_utc\"]))\n",
    "#         print(\"...\")\n",
    "        \n",
    "#         print(post[\"title\"] + \" \" + post[\"author\"] + str(post[\"created_utc\"]) + post[\"selftext\"] \n",
    "#               + post[\"id\"] + str(post[\"score\"]) + str(post[\"num_comments\"]))\n",
    "        \n",
    "        \n",
    "        if (\".jpg\" in post[\"url\"] or \".png\" in post[\"url\"] or \".tiff\" in post[\"url\"] or \".gif\" in post[\"url\"]):\n",
    "            posts_dict[\"Image URL\"].append(str(post[\"url\"]))\n",
    "            if (download_pictures):\n",
    "                download_pictures(str(post[\"url\"]))\n",
    "\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "        # Title of each post\n",
    "        posts_dict[\"Title\"].append(post[\"title\"])\n",
    "\n",
    "        # Author of each post\n",
    "        posts_dict[\"Author\"].append(str(post[\"author\"]))\n",
    "\n",
    "        # Time post was created\n",
    "        posts_dict[\"Timestamp\"].append(datetime.datetime.fromtimestamp(post[\"created_utc\"]).strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "\n",
    "        # Text inside a post\n",
    "        posts_dict[\"Post Text\"].append(post[\"selftext\"])\n",
    "\n",
    "        # Unique ID of each post\n",
    "        posts_dict[\"ID\"].append(post[\"id\"])\n",
    "\n",
    "        # The score of a post\n",
    "        posts_dict[\"Score\"].append(post[\"score\"])\n",
    "\n",
    "        # Total number of comments inside the post\n",
    "        posts_dict[\"Total Comments\"].append(str(post[\"num_comments\"]))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83333027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmaw import PushshiftAPI\n",
    "# http://web.archive.org/web/20210123052853/https://pushshift.io/api-parameters/\n",
    "# https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/\n",
    "\n",
    "api = PushshiftAPI()\n",
    "\n",
    "# Settings\n",
    "subreddit = \"ukrainememes\"\n",
    "chunk_size = 100\n",
    "reps = 10\n",
    "\n",
    "posts_dict = {\n",
    "    \"Title\": [], \"Author\" : [], \"Timestamp\" : [], \"Post Text\": [], \n",
    "    \"ID\": [], \"Score\": [], \"Total Comments\": [], \"Image URL\": []\n",
    "}\n",
    "    \n",
    "for x in range(reps):\n",
    "    if (x == 0):\n",
    "        last_time = int(time.time())\n",
    "    else:\n",
    "        last_time = post_list[len(post_list)-1][\"created_utc\"]\n",
    "    \n",
    "    posts = api.search_submissions(\n",
    "        subreddit=subreddit, \n",
    "        limit=chunk_size,\n",
    "        before=last_time\n",
    "    )\n",
    "    read_posts([post for post in posts], posts_dict)\n",
    "\n",
    "# Displaying the data in a pandas dataframe (for testing purposes)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts\n",
    "    \n",
    "    \n",
    "    \n",
    "#use loop and create multiple requests inside of it\n",
    "# use before parameter in loop?\n",
    "\n",
    "# sort by time or by popularity?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e404c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
